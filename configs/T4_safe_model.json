{
    "model": {
        "vocab_size": 50257,
        "context_length": 2048,
        "n_layers": 24,
        "n_heads": 16,
        "n_kv_heads": 4,
        "n_embd": 1024,
        "dropout": 0.1,
        "bias": false,
        "use_rope": true,
        "use_rmsnorm": true,
        "use_swiglu": true,
        "flash_attention": true,
        "use_gradient_checkpointing": true
    },
    "training": {
        "batch_size": 1,
        "gradient_accumulation_steps": 4,
        "max_epochs": 10,
        "learning_rate": 6e-4,
        "weight_decay": 0.1,
        "max_grad_norm": 1.0,
        "use_amp": true,
        "early_stop_patience": 3,
        "save_interval": 1000,
        "checkpoint_dir": "checkpoints_t4"
    },
    "data": {
        "block_size": 2048,
        "stride": 1024
    }
}
